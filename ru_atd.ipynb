{"cells":[{"cell_type":"markdown","metadata":{"id":"zg2r-EXcqtk1"},"source":["# RuATD22 Competition (binary task)"]},{"cell_type":"markdown","metadata":{},"source":["* https://github.com/dialogue-evaluation/RuATD\n","* Leaderboard: https://www.kaggle.com/c/ruatd-2022-bi/leaderboard"]},{"cell_type":"markdown","metadata":{},"source":["# Colab env"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27996,"status":"ok","timestamp":1645787472011,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"HQY4OfJ3M2dT","outputId":"8d101c9c-881b-436c-9cfb-5794239aa870"},"outputs":[],"source":["!pip install transformers tokenizers datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15528,"status":"ok","timestamp":1645787498563,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"nn2eWXSMqp7F","outputId":"ffb3c1ec-1b09-42eb-d90d-b8ac5b975f0e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1611,"status":"ok","timestamp":1645787500171,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"hZXP7GIZrKQs","outputId":"c790e242-b509-48bf-9cd7-f4aec0217b93"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/kaggle/ruatd22_competion\n"]}],"source":["%cd /content/drive/MyDrive/Colab\\ Notebooks/kaggle/ruatd22_competion"]},{"cell_type":"markdown","metadata":{},"source":["# Common env"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":11035,"status":"ok","timestamp":1645787483038,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"odJQ2pztqiO1"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import pickle\n","from tqdm import tqdm\n","import os\n","import time\n","from joblib import dump, load\n","\n","from sklearn.linear_model import LogisticRegression, SGDClassifier\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.base import BaseEstimator, ClassifierMixin\n","from sklearn.ensemble import VotingClassifier, HistGradientBoostingClassifier\n","from sklearn.neural_network import MLPClassifier\n","\n","from scipy import stats\n","from transformers import (AutoModelForSequenceClassification, AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, EarlyStoppingCallback, AutoConfig)\n","from datasets import Dataset, load_metric, Features, ClassLabel, Value\n","from tokenizers.decoders import ByteLevel\n","\n","from typing import Optional, Callable, Tuple, List"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":210,"status":"ok","timestamp":1645787560626,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"QNrF4fdkMw67"},"outputs":[],"source":["# Подготовка набора данных для BERT\n","\n","def build_dataset(data: pd.DataFrame, tokenizer: AutoTokenizer, max_length=512, with_label=True):\n","    if with_label:\n","        class_names = [\"M\", \"H\"]\n","        features = Features({'Text': Value('string'), 'label': ClassLabel(names=class_names, num_classes=2)})\n","        dataset = Dataset.from_pandas(data, preserve_index=False, features=features)\n","        dataset = dataset.map(lambda e: tokenizer(e['Text'], truncation=True, padding='max_length', max_length=max_length), batched=True)    \n","        dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n","    else:\n","        dataset = Dataset.from_pandas(data, preserve_index=False)\n","        dataset = dataset.map(lambda e: tokenizer(e['Text'], truncation=True, padding='max_length', max_length=max_length), batched=True)    \n","        dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask'])\n","    return dataset"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Сохраняем файл с предсказаниями переданного классификатора\n","\n","def submission(clf, X: np.ndarray, df: pd.DataFrame, out_suffix: str=\"\"):\n","    clf_pred = clf.predict(X)\n","    df['label'] = clf_pred\n","    df.loc[df['label'] == 0, 'Class'] = 'M'\n","    df.loc[df['label'] == 1, 'Class'] = 'H'\n","    df.to_csv(f'submission_{out_suffix}.csv', columns=['Id','Class'], index=False)  "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["ds_path = './dataset/'\n","cp_path = 'test_trainer/checkpoint-8068'"]},{"cell_type":"markdown","metadata":{"id":"45xB2Kf5yXWF"},"source":["# RuATD Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4955,"status":"ok","timestamp":1645787505125,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"2VduU_KrqiO6","outputId":"6d27e3e4-66ff-4e31-c93c-2d982c705612"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 129066 entries, 0 to 129065\n","Data columns (total 4 columns):\n"," #   Column  Non-Null Count   Dtype \n","---  ------  --------------   ----- \n"," 0   Id      129066 non-null  Int64 \n"," 1   Text    129066 non-null  string\n"," 2   Class   129066 non-null  string\n"," 3   label   129066 non-null  Int64 \n","dtypes: Int64(2), string(2)\n","memory usage: 4.2 MB\n"]}],"source":["df_train = pd.read_csv(os.path.join(ds_path, 'train.csv'))\n","df_train.loc[df_train['Class'] == 'M', 'label'] = 0\n","df_train.loc[df_train['Class'] == 'H', 'label'] = 1\n","df_train = df_train.convert_dtypes()\n","\n","y_train = df_train['label'].to_numpy(dtype=np.int8)\n","\n","df_train.info()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1087,"status":"ok","timestamp":1645787506210,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"aZZ48y_oMw6o","outputId":"5f26111a-0c2d-4160-9869-db174a0a10aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 21511 entries, 0 to 21510\n","Data columns (total 4 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   Id      21511 non-null  Int64 \n"," 1   Text    21511 non-null  string\n"," 2   Class   21511 non-null  string\n"," 3   label   21511 non-null  Int64 \n","dtypes: Int64(2), string(2)\n","memory usage: 714.4 KB\n"]}],"source":["df_val = pd.read_csv(os.path.join(ds_path, 'val.csv'))\n","df_val.loc[df_val['Class'] == 'M', 'label'] = 0\n","df_val.loc[df_val['Class'] == 'H', 'label'] = 1\n","df_val = df_val.convert_dtypes()\n","\n","y_val = df_val['label'].to_numpy(dtype=np.int8)\n","\n","df_val.info()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1096,"status":"ok","timestamp":1645787581847,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"MogazM32lLxX"},"outputs":[],"source":["df_test = pd.read_csv(os.path.join(ds_path, 'test.csv'))"]},{"cell_type":"markdown","metadata":{"id":"NBz7augvpuu1"},"source":["## Features Dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"W51wXviXpuu1"},"outputs":[],"source":["feats_path = './others/Data/features'"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"o3V0C2swpuu1"},"outputs":[],"source":["# train\n","\n","with open(os.path.join(feats_path, 'train_feats.pkl'), 'rb') as f:\n","    train_feats = pickle.load(f)\n","\n","with open(os.path.join(feats_path, 'train_QFT.pkl'), 'rb') as f:\n","    train_qfeats = pickle.load(f)\n","\n","x_train_feats = np.hstack((train_feats, train_qfeats))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"87J74Q7lpuu2"},"outputs":[],"source":["# val\n","\n","with open(os.path.join(feats_path, 'val_feats.pkl'), 'rb') as f:\n","    val_feats = pickle.load(f)\n","\n","with open(os.path.join(feats_path, 'val_QFT.pkl'), 'rb') as f:\n","    val_qfeats = pickle.load(f)\n","\n","x_val_feats = np.hstack((val_feats, val_qfeats))\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ycODKZ9AHjm4"},"outputs":[],"source":["# test\n","\n","with open(os.path.join(feats_path, 'test_feats.pkl'), 'rb') as f:\n","    test_feats = pickle.load(f)\n","\n","with open(os.path.join(feats_path, 'test_QFT.pkl'), 'rb') as f:\n","   test_qfeats = pickle.load(f)\n","\n","x_test_feats = np.hstack((test_feats, test_qfeats))"]},{"cell_type":"markdown","metadata":{"id":"AcwHv_s8Mw6p"},"source":["# 1. GLTR"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"dYut8zThqiO4"},"outputs":[],"source":["def top_k_logits(logits, k):\n","    \"\"\"\n","    Filters logits to only the top k choices\n","    from https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_gpt2.py\n","    \"\"\"\n","    if k == 0:\n","        return logits\n","    values, _ = torch.topk(logits, k)\n","    min_values = values[:, -1]\n","    return torch.where(logits < min_values,\n","                       torch.ones_like(logits, dtype=logits.dtype) * -1e10,\n","                       logits)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"epdYZhK1qiO3"},"outputs":[],"source":["class AbstractLanguageChecker:\n","    \"\"\"\n","    Abstract Class that defines the Backend API of GLTR.\n","\n","    To extend the GLTR interface, you need to inherit this and\n","    fill in the defined functions.\n","    \"\"\"\n","\n","    def __init__(self):\n","        \"\"\"\n","        In the subclass, you need to load all necessary components\n","        for the other functions.\n","        Typically, this will comprise a tokenizer and a model.\n","        \"\"\"\n","        self.device = torch.device(\n","            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    def check_probabilities(self, in_text, topk=40):\n","        \"\"\"\n","        Function that GLTR interacts with to check the probabilities of words\n","\n","        Params:\n","        - in_text: str -- The text that you want to check\n","        - topk: int -- Your desired truncation of the head of the distribution\n","\n","        Output:\n","        - payload: dict -- The wrapper for results in this function, described below\n","\n","        Payload values\n","        ==============\n","        bpe_strings: list of str -- Each individual token in the text\n","        real_topk: list of tuples -- (ranking, prob) of each token\n","        pred_topk: list of list of tuple -- (word, prob) for all topk\n","        \"\"\"\n","        raise NotImplementedError\n","\n","    def postprocess(self, token):\n","        \"\"\"\n","        clean up the tokens from any special chars and encode\n","        leading space by UTF-8 code '\\u0120', linebreak with UTF-8 code 266 '\\u010A'\n","        :param token:  str -- raw token text\n","        :return: str -- cleaned and re-encoded token text\n","        \"\"\"\n","        raise NotImplementedError\n","\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"9C3CDakUqiO5"},"outputs":[],"source":["class RuLM(AbstractLanguageChecker):\n","    def __init__(self, model_name_or_path=\"sberbank-ai/rugpt3small_based_on_gpt2\"):\n","        super(RuLM, self).__init__()\n","        self.enc = AutoTokenizer.from_pretrained(model_name_or_path)\n","        self.enc.add_special_tokens({'bos_token': '<s>'})\n","\n","        self.model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n","        self.model.resize_token_embeddings(len(self.enc))\n","        print(\"Device:\", self.device)\n","        self.model.to(self.device)\n","        self.model.eval()\n","        self.start_token = self.enc('<s>', return_tensors='pt').data['input_ids'][0]\n","        self.decoder = ByteLevel()\n","        # self.start_token = self.enc.eos_token_id\n","        print(\"Loaded GPT-3 model!\")\n","\n","    def check_probabilities(self, in_text, topk=40):\n","        # Process input\n","        token_ids = self.enc(in_text, return_tensors='pt').data['input_ids'][0]\n","        token_ids = torch.concat([self.start_token, token_ids])\n","        # Forward through the model\n","        output = self.model(token_ids.to(self.device))\n","        all_logits = output.logits[:-1].detach().squeeze()\n","        # construct target and pred\n","        # yhat = torch.softmax(logits[0, :-1], dim=-1)\n","        all_probs = torch.softmax(all_logits, dim=1)\n","\n","        y = token_ids[1:]\n","        # Sort the predictions for each timestep\n","        sorted_preds = torch.argsort(all_probs, dim=1, descending=True).cpu()\n","        # [(pos, prob), ...]\n","        real_topk_pos = list(\n","            [int(np.where(sorted_preds[i] == y[i].item())[0][0])\n","             for i in range(y.shape[0])])\n","        real_topk_probs = all_probs[np.arange(0, y.shape[0], 1), y].data.cpu().numpy().tolist()\n","        real_topk_probs = list(map(lambda x: round(x, 5), real_topk_probs))\n","\n","        real_topk = list(zip(real_topk_pos, real_topk_probs))\n","        # [str, str, ...]\n","        bpe_strings = [self.decoder.decode([self.enc.convert_ids_to_tokens(tok.item())]) for tok in token_ids[:]]\n","\n","        bpe_strings = [self.postprocess(s) for s in bpe_strings]\n","\n","        topk_prob_values, topk_prob_inds = torch.topk(all_probs, k=topk, dim=1)\n","\n","        pred_topk = [list(zip([self.decoder.decode(self.enc.convert_ids_to_tokens(tok.item())) for tok in topk_prob_inds[i]] ,\n","                              topk_prob_values[i].data.cpu().numpy().tolist()\n","                              )) for i in range(y.shape[0])]\n","        pred_topk = [[(self.postprocess(t[0]), t[1]) for t in pred] for pred in pred_topk]\n","\n","\n","        # pred_topk = []\n","        payload = {'bpe_strings': bpe_strings,\n","                   'real_topk': real_topk,\n","                   'pred_topk': pred_topk}\n","        if torch.cuda.is_available():\n","            torch.cuda.empty_cache()\n","\n","        return payload\n","\n","    def sample_unconditional(self, length=100, topk=5, temperature=1.0):\n","        '''\n","        Sample `length` words from the model.\n","        Code strongly inspired by\n","        https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_gpt2.py\n","\n","        '''\n","        context = torch.full((1, 1),\n","                             self.enc.encoder['<s>'],\n","                             device=self.device,\n","                             dtype=torch.long)\n","        prev = context\n","        output = context\n","        # Forward through the model\n","        with torch.no_grad():\n","            for i in range(length):\n","                logits = self.model(prev).logits\n","                logits = logits[:, -1, :] / temperature\n","                # Filter predictions to topk and softmax\n","                probs = torch.softmax(top_k_logits(logits, k=topk),\n","                                      dim=-1)\n","                # Sample\n","                prev = torch.multinomial(probs, num_samples=1)\n","                # Construct output\n","                output = torch.cat((output, prev), dim=1)\n","\n","        output_text = self.enc.decode(output[0].tolist())\n","        return output_text\n","\n","    def postprocess(self, token):\n","        with_space = False\n","        with_break = False\n","        if token.startswith('Ġ'):\n","            with_space = True\n","            token = token[1:]\n","            # print(token)\n","        elif token.startswith('â'):\n","            token = ' '\n","        elif token.startswith('Ċ'):\n","            token = ' '\n","            with_break = True\n","\n","        token = '-' if token.startswith('â') else token\n","        token = '“' if token.startswith('ľ') else token\n","        token = '”' if token.startswith('Ŀ') else token\n","        token = \"'\" if token.startswith('Ļ') else token\n","\n","        if with_space:\n","            token = '\\u0120' + token\n","        if with_break:\n","            token = '\\u010A' + token\n","\n","        return token"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"kbifeB6_qiO6"},"outputs":[],"source":["def real_topk_count(payload: dict) -> dict:    \n","    ids = np.array([x[0] for x in payload['real_topk']])\n","    topk_10 = ids[ids < 10]\n","    topk_100 = ids[np.where(np.logical_and(ids >= 10, ids < 100))]\n","    topk_1000 = ids[np.where(np.logical_and(ids >= 100, ids < 1000))]\n","    topk_over_1000 = ids[ids > 1000]\n","\n","    frac_p = [payload['real_topk'][i][1] / np.max([x[1] for x in payload['pred_topk'][i]]) for i in range(len(payload['real_topk']))]\n","\n","    threshold = 10\n","    pred_probs_normal = [[ x[1] for x in payload['pred_topk'][i][:threshold] ] for i in range(len(payload['pred_topk']))] \n","    pred_probs_normal = [[y / sum(x) for y in x] for x in pred_probs_normal]  \n","    frac_entr = stats.entropy(pred_probs_normal, axis=1)\n","\n","    return {'topk_10': np.round(len(topk_10) / len(ids), 4),\n","            'topk_100': np.round(len(topk_100) / len(ids), 4),\n","            'topk_1000': np.round(len(topk_1000) / len(ids), 4),\n","            'topk_over_1000': np.round(len(topk_over_1000) / len(ids), 4),\n","            'frac_p_median': np.round(np.median(frac_p), 4),\n","            'frac_entr_median': np.round(np.median(frac_entr), 4),\n","            'tokens_size': len(ids)}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MrcKLntxubd-"},"outputs":[],"source":["# Выбираем часть примеров из выборки  в одинаковой пропорции классов\n","\n","idx_limit = 10000\n","df_train_limited = pd.concat([df_train[df_train['Class'] == 'M'][:idx_limit], df_train[df_train['Class'] == 'H'][:idx_limit]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wf1RF4cgqiO6"},"outputs":[],"source":["# Получаем распределения токенов по примерам выборки\n","\n","lm = RuLM()\n","train_payload = []\n","for raw_text in tqdm(df_train_limited['Text']):\n","    payload = lm.check_probabilities(raw_text, topk=20)\n","    train_payload.append(payload)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_M6YtP_rqiO7"},"outputs":[],"source":["with open(os.path.join(ds_path, 'train_payload.pkl'), 'wb') as f:    \n","    pickle.dump(train_payload, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ex7RXUvfqiO8"},"outputs":[],"source":["with open(os.path.join(ds_path, 'train_payload.pkl'), 'rb') as f:    \n","    new_train_payload = pickle.load(f)\n","\n","print(len(new_train_payload))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zRNCNXfyqiO8"},"outputs":[],"source":["# извлекаем признаки из распределений токенов\n","\n","df_topk = pd.DataFrame.from_dict([real_topk_count(payload) for payload in tqdm(new_train_payload)])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1BsmLB9B9W2d"},"outputs":[],"source":["df_train_limited.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wRGSx1ECqiO8"},"outputs":[],"source":["df_train_topk = pd.DataFrame.join(df_train_limited, df_topk)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L6DRyCwFqiO9"},"outputs":[],"source":["df_train_topk.to_pickle(os.path.join(ds_path, 'df_train_topk.pkl'))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"m-T2sFnL923_"},"outputs":[],"source":["df_new = pd.read_pickle(os.path.join(ds_path, 'df_train_topk.pkl')) "]},{"cell_type":"code","execution_count":13,"metadata":{"id":"VaPsaIqE-OKP"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 20000 entries, 0 to 19999\n","Data columns (total 10 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   Id                20000 non-null  int64  \n"," 1   Text              20000 non-null  object \n"," 2   Class             20000 non-null  object \n"," 3   topk_10           20000 non-null  float64\n"," 4   topk_100          20000 non-null  float64\n"," 5   topk_1000         20000 non-null  float64\n"," 6   topk_over_1000    20000 non-null  float64\n"," 7   frac_p_median     20000 non-null  float64\n"," 8   frac_entr_median  20000 non-null  float64\n"," 9   tokens_size       20000 non-null  int64  \n","dtypes: float64(6), int64(2), object(2)\n","memory usage: 1.5+ MB\n"]}],"source":["df_new.info()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Text</th>\n","      <th>Class</th>\n","      <th>topk_10</th>\n","      <th>topk_100</th>\n","      <th>topk_1000</th>\n","      <th>topk_over_1000</th>\n","      <th>frac_p_median</th>\n","      <th>frac_entr_median</th>\n","      <th>tokens_size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>Минстрой обозначил способы снижения энергоемко...</td>\n","      <td>M</td>\n","      <td>0.4167</td>\n","      <td>0.3333</td>\n","      <td>0.0833</td>\n","      <td>0.1667</td>\n","      <td>0.1913</td>\n","      <td>1.9226</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>В конце 1873 года военный суд вынес решение по...</td>\n","      <td>M</td>\n","      <td>0.5789</td>\n","      <td>0.1053</td>\n","      <td>0.1579</td>\n","      <td>0.1579</td>\n","      <td>0.0352</td>\n","      <td>1.6375</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13</td>\n","      <td>Земная атмосфера не имеет ничего общего со сти...</td>\n","      <td>M</td>\n","      <td>0.9219</td>\n","      <td>0.0547</td>\n","      <td>0.0156</td>\n","      <td>0.0078</td>\n","      <td>0.4203</td>\n","      <td>1.6183</td>\n","      <td>128</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>18</td>\n","      <td>Жертва вводит данные банковской карты или крип...</td>\n","      <td>M</td>\n","      <td>0.4286</td>\n","      <td>0.2143</td>\n","      <td>0.1429</td>\n","      <td>0.2143</td>\n","      <td>0.0676</td>\n","      <td>1.7483</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>26</td>\n","      <td>В голове в духе 461-го года, а я сижу дома и д...</td>\n","      <td>M</td>\n","      <td>0.6494</td>\n","      <td>0.3384</td>\n","      <td>0.0076</td>\n","      <td>0.0046</td>\n","      <td>0.1923</td>\n","      <td>1.9237</td>\n","      <td>656</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Id                                               Text Class  topk_10  \\\n","0   3  Минстрой обозначил способы снижения энергоемко...     M   0.4167   \n","1   4  В конце 1873 года военный суд вынес решение по...     M   0.5789   \n","2  13  Земная атмосфера не имеет ничего общего со сти...     M   0.9219   \n","3  18  Жертва вводит данные банковской карты или крип...     M   0.4286   \n","4  26  В голове в духе 461-го года, а я сижу дома и д...     M   0.6494   \n","\n","   topk_100  topk_1000  topk_over_1000  frac_p_median  frac_entr_median  \\\n","0    0.3333     0.0833          0.1667         0.1913            1.9226   \n","1    0.1053     0.1579          0.1579         0.0352            1.6375   \n","2    0.0547     0.0156          0.0078         0.4203            1.6183   \n","3    0.2143     0.1429          0.2143         0.0676            1.7483   \n","4    0.3384     0.0076          0.0046         0.1923            1.9237   \n","\n","   tokens_size  \n","0           12  \n","1           19  \n","2          128  \n","3           14  \n","4          656  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df_new.head()"]},{"cell_type":"markdown","metadata":{"id":"-RNaPfGjQfBM"},"source":["## Model"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"aORyO8IMQfBN"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topk_10</th>\n","      <th>topk_100</th>\n","      <th>topk_1000</th>\n","      <th>topk_over_1000</th>\n","      <th>frac_p_median</th>\n","      <th>frac_entr_median</th>\n","      <th>tokens_size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.4167</td>\n","      <td>0.3333</td>\n","      <td>0.0833</td>\n","      <td>0.1667</td>\n","      <td>0.1913</td>\n","      <td>1.9226</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.5789</td>\n","      <td>0.1053</td>\n","      <td>0.1579</td>\n","      <td>0.1579</td>\n","      <td>0.0352</td>\n","      <td>1.6375</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.9219</td>\n","      <td>0.0547</td>\n","      <td>0.0156</td>\n","      <td>0.0078</td>\n","      <td>0.4203</td>\n","      <td>1.6183</td>\n","      <td>128</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.4286</td>\n","      <td>0.2143</td>\n","      <td>0.1429</td>\n","      <td>0.2143</td>\n","      <td>0.0676</td>\n","      <td>1.7483</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.6494</td>\n","      <td>0.3384</td>\n","      <td>0.0076</td>\n","      <td>0.0046</td>\n","      <td>0.1923</td>\n","      <td>1.9237</td>\n","      <td>656</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   topk_10  topk_100  topk_1000  topk_over_1000  frac_p_median  \\\n","0   0.4167    0.3333     0.0833          0.1667         0.1913   \n","1   0.5789    0.1053     0.1579          0.1579         0.0352   \n","2   0.9219    0.0547     0.0156          0.0078         0.4203   \n","3   0.4286    0.2143     0.1429          0.2143         0.0676   \n","4   0.6494    0.3384     0.0076          0.0046         0.1923   \n","\n","   frac_entr_median  tokens_size  \n","0            1.9226           12  \n","1            1.6375           19  \n","2            1.6183          128  \n","3            1.7483           14  \n","4            1.9237          656  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["df_new.loc[:,'topk_10':'tokens_size'].head()"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"b-POJqt3QfBN"},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(df_new.loc[:,'topk_10':'tokens_size'], df_new['Class'], test_size=0.1)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"kS1o7v-WQfBN"},"outputs":[{"data":{"text/plain":["LabelEncoder()"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["encoder = LabelEncoder()\n","encoder.fit(y_train)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"j13JNIKVQfBN"},"outputs":[],"source":["y_train_enc = encoder.transform(y_train)\n","y_test_enc = encoder.transform(y_test)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"uNufrB4fQfBN"},"outputs":[{"data":{"text/plain":["LogisticRegression()"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["clf = LogisticRegression()\n","clf.fit(x_train, y_train_enc)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"JmvuvIxCQfBO"},"outputs":[],"source":["y_test_pred = clf.predict(x_test)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"s-jnzNGUQfBO"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.59      0.48      0.53      1023\n","           1       0.54      0.65      0.59       977\n","\n","    accuracy                           0.56      2000\n","   macro avg       0.57      0.57      0.56      2000\n","weighted avg       0.57      0.56      0.56      2000\n","\n","[[489 534]\n"," [338 639]]\n"]}],"source":["print(classification_report(y_test_enc, y_test_pred))\n","print(confusion_matrix(y_test_enc, y_test_pred))"]},{"cell_type":"markdown","metadata":{"id":"ZQd5Qw2hMw66"},"source":["# 2. Feature Extraction"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"LQodV_f2puu3"},"outputs":[],"source":["def clf_eval(clf, x, y_true):\n","    y_pred = clf.predict(x)\n","    print(classification_report(y_true, y_pred))\n","    print(confusion_matrix(y_true, y_pred))"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["x_train = x_train_feats\n","x_val = x_val_feats\n","x_test = x_test_feats"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"hxlIlcMTpuu3"},"outputs":[],"source":["ct = ColumnTransformer([\n","        ('scaler', StandardScaler(), list(range(x_train.shape[1])))\n","    ], remainder='passthrough')\n","\n","x_train_scaled = ct.fit_transform(x_train)\n","x_val_scaled = ct.transform(x_val)\n","x_test_scaled = ct.transform(x_test)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"YMsUoWuNpuu4","outputId":"fb23bc42-e8a3-4c07-ed98-c1de6869f04d"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.74      0.76      0.75     10755\n","           1       0.75      0.73      0.74     10756\n","\n","    accuracy                           0.74     21511\n","   macro avg       0.74      0.74      0.74     21511\n","weighted avg       0.74      0.74      0.74     21511\n","\n","[[8132 2623]\n"," [2915 7841]]\n"]}],"source":["clf_lr = LogisticRegression(max_iter=1000, random_state=0, verbose=0).fit(x_train_scaled, y_train)\n","clf_eval(clf_lr, x_val_scaled, y_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5YyHY6owuzpi"},"outputs":[],"source":["lr_pred = clf_lr.predict(x_val_scaled)\n","np.save('val_logreg_pred.npy', lr_pred)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"rs3iipe8puu4","outputId":"e8a95ff7-b3a2-40a2-e2c6-11453cee4ee8"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.76      0.75      0.76     10755\n","           1       0.75      0.76      0.76     10756\n","\n","    accuracy                           0.76     21511\n","   macro avg       0.76      0.76      0.76     21511\n","weighted avg       0.76      0.76      0.76     21511\n","\n","[[8079 2676]\n"," [2540 8216]]\n"]}],"source":["clf_hgboost = HistGradientBoostingClassifier(random_state=0).fit(x_train_scaled, y_train)\n","clf_eval(clf_hgboost, x_val_scaled, y_val)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["submission(clf_hgboost, x_test_scaled, df_test, 'hgboost')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34xt_Pg8puu6"},"outputs":[],"source":["hgboost_pred = clf_hgboost.predict(x_val_scaled)\n","np.save('val_hgboost_pred.npy', hgboost_pred)"]},{"cell_type":"markdown","metadata":{"id":"b7vyEubCMw66"},"source":["# 3. BERT"]},{"cell_type":"markdown","metadata":{},"source":["Обучение выполнялось скриптами из каталога ./bert/"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":225,"status":"ok","timestamp":1645787588892,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"SYCYbT9uyXWn"},"outputs":[],"source":["model_loaded = AutoModelForSequenceClassification.from_pretrained(cp_path)\n","tokenizer_loaded = AutoTokenizer.from_pretrained(cp_path)"]},{"cell_type":"markdown","metadata":{"id":"VHtlJomBpuvC"},"source":["## Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["cbd01516d8b840faaeb0293c7b059c80","7db33ec8a86d43f18f633c2fb7c9bd98","f325051977c644d7b75bc4cc88d874bf","024b5beba4c3459099ac0a5312816bc6","80f10655527b44468a12bd58e5931527","7a83e698a1944cbea611ffbdc174b7c2","96f0bbdf65c1415e85ce421220e51078","39893bd6a9284642acc8d214b5e8aa53","43c9dd8b01eb4b049e59ede63b6fc3a9","530160f263e14ce0ab9dcb06215141c6","b921920c3f7842468f02deb23e284b04"]},"executionInfo":{"elapsed":5350,"status":"ok","timestamp":1645286914334,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"dy1nBWJ8puvD","outputId":"bc855247-ac2b-44b7-c103-9321fe6e4ef0"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cbd01516d8b840faaeb0293c7b059c80","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/22 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["ds_val = build_dataset(df_val, tokenizer_loaded, max_length=200, with_label=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":110},"executionInfo":{"elapsed":519629,"status":"ok","timestamp":1645287466291,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"w7H80JdkyjYN","outputId":"3b76096e-f302-4f49-9dc3-f4b3055a8df9"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Text.\n","***** Running Prediction *****\n","  Num examples = 21511\n","  Batch size = 64\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='337' max='337' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [337/337 08:26]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["training_args = TrainingArguments(\"eval_trainer\", \n","                                per_device_train_batch_size=64, \n","                                per_device_eval_batch_size=64,\n","                                do_train=False,\n","                                do_eval=False,\n","                                report_to=\"none\"\n","                                )\n","\n","trainer = Trainer(model=model_loaded, \n","                    args=training_args)\n","\n","val_preds = trainer.predict(ds_val).predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fmlq7Vwy3Dxb"},"outputs":[],"source":["np.save(os.path.join(ds_path, \"val_probs_bert\"), val_preds) # сохраняем логиты для использования в soft VotingClassifier "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snEU5hfv3KpH"},"outputs":[],"source":["val_preds = np.argmax(val_preds, axis=1) \n","np.save(os.path.join(ds_path, \"val_preds_bert\"), val_preds)"]},{"cell_type":"markdown","metadata":{"id":"GltbYq2ipuvE"},"source":["## Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SjQugYa0yXWm"},"outputs":[],"source":["df_test = pd.read_csv(os.path.join(ds_path, 'test.csv'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["3d82ff3720024a0e8f4c1c886d15ea1e","0e591ca82dbf4cbd8d271d419335e7da","296191f91c98486c8b049cd46588faa3","0f424e58531c4c3ba5ddfa6cdde28c36","ccaf3da3789949278f05bb209f1fa011","011bcd59702e4471bf344d7adc18ff4d","b7aa40022e0447489e2009e5ad95f300","1dd909aae6e94daf8ef367ea491266eb","48874d849d294cb2ae524ad2d0ecb36c","2768e23224c145dbbe7bf4c215d8e4a1","a7649e3843b44f3d8d40cb823e60d7a7"]},"executionInfo":{"elapsed":15315,"status":"ok","timestamp":1645360116642,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"7QJ8FZOnyXWn","outputId":"8fb874bf-57ee-4324-e72f-31c7c90e4848"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d82ff3720024a0e8f4c1c886d15ea1e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/65 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["ds_test = build_dataset(df_test, tokenizer_loaded, max_length=200, with_label=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":110},"executionInfo":{"elapsed":821150,"status":"ok","timestamp":1645360942737,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"Re4bD5RDyXWo","outputId":"80a8139f-a72a-4119-aa14-6b374672cf06"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Text, Id.\n","***** Running Prediction *****\n","  Num examples = 64533\n","  Batch size = 64\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1009' max='1009' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1009/1009 13:27]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["training_args = TrainingArguments(\"test_trainer\", \n","                                per_device_train_batch_size=64, \n","                                per_device_eval_batch_size=64,\n","                                do_train=False,\n","                                do_eval=False,\n","                                report_to=\"none\"\n","                                )\n","\n","trainer = Trainer(model=model_loaded, args=training_args)\n","test_preds = trainer.predict(ds_test).predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1645360942737,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"B5C_lyroGKvG","outputId":"d0637f4e-f0fd-4b43-df25-b531327388f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 4.5222025 -4.2354918]\n"]}],"source":["np.save(os.path.join(ds_path, \"test_bert_prob\"), test_preds) # сохраняем логиты для использования в soft VotingClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mm9gP5b4yXWo"},"outputs":[],"source":["test_preds_labels = np.argmax(test_preds, axis=1)\n","np.save(os.path.join(ds_path, \"test_bert_pred\"), test_preds_labels) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gpOSYOLryXWo"},"outputs":[],"source":["df_test['label'] = test_preds_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"orHFOEPcyXWp"},"outputs":[],"source":["df_test.loc[df_test['label'] == 0, 'Class'] = 'M'\n","df_test.loc[df_test['label'] == 1, 'Class'] = 'H'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OZJ0zVKwyXWq"},"outputs":[],"source":["df_test.to_csv('submission.csv', columns=['Id','Class'], index=False) "]},{"cell_type":"markdown","metadata":{"id":"tmOWpkLpFxHd"},"source":["# 4. Ансамбль классификаторов"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train = x_train_feats\n","x_val = x_val_feats\n","x_test = x_test_feats"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ct = ColumnTransformer([\n","        ('scaler', StandardScaler(), list(range(x_train.shape[1])))\n","    ], remainder='passthrough')\n","\n","x_train_scaled = ct.fit_transform(x_train)\n","x_val_scaled = ct.transform(x_val)\n","x_test_scaled = ct.transform(x_test)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"95bRpT09FxHg"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nhF-9JbXFxHh"},"outputs":[],"source":["# По факту класс для классификатора BERT в работе не использовался, вместо него применялся класс заглушка для ускорения эксперимента\n","\n","class BertClassifiier(BaseEstimator, ClassifierMixin):\n","    def __init__(\n","            self,\n","            bert_tokenizer,\n","            bert_model,\n","            max_length: int = 512):\n","        \n","        self.tokenizer = bert_tokenizer\n","        self.model = bert_model\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.model.eval().to(self.device)\n","        self.max_length = max_length\n","   \n","    def fit(self, X, y=None):\n","        return self\n","\n","    def predict_proba(self, X, y=None):\n","        dataset = build_dataset(X, self.tokenizer, max_length=200, with_label=False)\n","        training_args = TrainingArguments(\"eval_trainer\", \n","                                per_device_train_batch_size=64, \n","                                per_device_eval_batch_size=64,\n","                                do_train=False,\n","                                do_eval=False,\n","                                report_to=\"none\"\n","                                )\n","        \n","        trainer = Trainer(model=self.model, args=training_args)\n","        \n","        return trainer.predict(dataset).predictions"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"vn8Vwu1lFxHh"},"outputs":[],"source":["# Классификатор Bert заглушка, которая работает уже готовыми предсказаниями BERT. Сделано для ускорение эксперимента\n","\n","class DummyBertClassifiier(BaseEstimator, ClassifierMixin):    \n","    def __init__(self, dataset: str='val'):\n","        self.dataset = dataset\n","\n","    def fit(self, X, y=None):\n","        \"\"\"Классификатор не учится, потому что использует готовые предсказания\"\"\"\n","        return self\n","\n","    def predict_proba(self, X, y=None):\n","        result=None\n","        if self.dataset == 'val':\n","            result = np.load(\"val_bert_prob.npy\")\n","        elif self.dataset == 'test':\n","            result = np.load(\"test_bert_prob.npy\")         \n","        return result"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":119270,"status":"ok","timestamp":1645361631231,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"W9qroQhHFxHi","outputId":"24beaf3b-4f16-48d9-9834-f1fe0fc14274"},"outputs":[{"data":{"text/plain":["VotingClassifier(estimators=[('hist_gb',\n","                              HistGradientBoostingClassifier(random_state=0)),\n","                             ('lr',\n","                              LogisticRegression(max_iter=5000,\n","                                                 random_state=0)),\n","                             ('bert', DummyBertClassifiier(dataset='test'))],\n","                 voting='soft')"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["clf_bert_dummy = DummyBertClassifiier(dataset='test')\n","clf_hgboost = HistGradientBoostingClassifier(random_state=0)\n","clf_lr = LogisticRegression(max_iter=5000, random_state=0, verbose=0)\n","\n","eclf_soft = VotingClassifier(estimators=[('hist_gb', clf_hgboost), ('lr', clf_lr), ('bert', clf_bert_dummy)], voting='soft')\n","eclf_soft.fit(x_train_scaled, y_train)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["submission(clf=eclf_soft, X=x_test_scaled, df=df_test, out_suffix='eclf_soft')"]},{"cell_type":"markdown","metadata":{"id":"ZrK43My3ZipG"},"source":["# 5. Комбинация признаков"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["model_loaded = AutoModelForSequenceClassification.from_pretrained(cp_path)\n","tokenizer_loaded = AutoTokenizer.from_pretrained(cp_path)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["17de390efd7348a392aca4d76c36f276","1713bdd29a5c439382b6806bebd95edd","0fbcbb759407479eb12db76f5c347f1a","f6dff8192b8b4e66bb75a53d919d2506","39d7bcaa318a4dcd9ab8654ccb59b33b","1a4768f86f634af1a378f1ab87c98b9b","1aea4571b9ea493183b026a71058b604","8e842de07d6d41df9855b6f727487f7b","6225b8f9625d4bc8b4f370c623239f80","c492521bea4d4b3184bbbb103a4d0836","be4ce3f011984b3ba609ce8f7a07c9f0","07464f6c62024a798cee0acf98c011e3","465078bfeb3d40439dc09f427ccfbe14","d6a99adeb6cb487dbe402199371b4751","c9150df8ab334a19838d1c9fc97fa4b1","dd30acc473e043d78e929f886191a40f","651a4b33e03a4c30a3bc70d76290d948","955eb95850f84ba3af23588c6b622ef2","1f02ec40c23c4b19acd5841ba682c49c","1e10688073f544018a38ef40e25bcb0c","e9d9a59206b44d24900997c0c00b9c6f","ebf4b2bbef7d47d4aefc93b4ea0a1b3f","a5044d791c014c4c83aa531f99ed3d56","e41629ea77e643f8a0c45a502399bf4f","35e0bbce8e61460ea3a5eb193207e8cb","8bb5f42b01664a67af782484da70cbce","19de5c9ce041491b82b875e4e908dd31","4b7a10def477422f92548316455516d4","8ec4ac73432f48ffad3e570d5d8d6986","72f8bd31aa944771ae512a536a25376b","25b6623edb6747d8ae6b63f458c8d752","b9ea31aa509f48a6958ef0a5a2da9713","83db1745ca8a46518228d00431d056d4"]},"executionInfo":{"elapsed":60261,"status":"ok","timestamp":1645787662094,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"6ZMAqduQZipG","outputId":"5bb691ab-a72c-40cf-d713-ef83c7d8f2bf"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 130/130 [00:18<00:00,  6.99ba/s]\n","100%|██████████| 22/22 [00:04<00:00,  5.09ba/s]\n","100%|██████████| 65/65 [00:10<00:00,  6.11ba/s]\n"]}],"source":["ds_train = build_dataset(df_train, tokenizer_loaded, max_length=200, with_label=False)\n","ds_val = build_dataset(df_val, tokenizer_loaded, max_length=200, with_label=False)\n","ds_test = build_dataset(df_test, tokenizer_loaded, max_length=200, with_label=False)\n","train_loader = torch.utils.data.DataLoader(ds_train, shuffle=False, batch_size=32)\n","val_loader = torch.utils.data.DataLoader(ds_val, shuffle=False, batch_size=32)\n","test_loader = torch.utils.data.DataLoader(ds_test, shuffle=False, batch_size=32)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15652,"status":"ok","timestamp":1645787677998,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"7eiU67LhZipG","outputId":"69521c2c-1594-4b30-902a-566ddcd46000"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]},{"data":{"text/plain":["Sequential(\n","  (0): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n",")"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# Берутся все слои Bert без выходного слоя классификатора\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)\n","\n","model_nohead = torch.nn.Sequential(list(model_loaded.children())[0])\n","model_nohead.eval().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1621015,"status":"ok","timestamp":1645776826651,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"G49IXOpOZipG","outputId":"ec9edfb7-9e37-4b92-fedd-ef45f8c42314"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 4034/4034 [27:00<00:00,  2.49it/s]\n"]}],"source":["with torch.no_grad():\n","        x_train_bert = torch.vstack([model_nohead(batch['input_ids'].to(device)).last_hidden_state[:,0].detach().to('cpu') for batch in tqdm(train_loader)])\n","\n","np.save(os.path.join(ds_path, 'x_train_emb.npy'), x_train_bert.numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269586,"status":"ok","timestamp":1645777099842,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"7DKsaElqar_G","outputId":"6ed4cbaf-6574-453f-f6c6-1c2df40bd372"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 673/673 [04:29<00:00,  2.50it/s]\n"]}],"source":["with torch.no_grad():\n","        x_val_bert = torch.vstack([model_nohead(batch['input_ids'].to(device)).last_hidden_state[:,0].detach().to('cpu') for batch in tqdm(val_loader)])\n","np.save(os.path.join(ds_path, 'x_val_emb.npy'), x_val_bert.numpy())"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1501715,"status":"ok","timestamp":1645789179702,"user":{"displayName":"Эдуард Белов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUoGPf2r7rB_QQBVMBeXyasI8qHdiNJV7wpyZD=s64","userId":"14607229745996081628"},"user_tz":-180},"id":"qk9okW_ukehv","outputId":"893868ba-3d8f-456c-dd11-4367888accde"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2017/2017 [25:01<00:00,  1.34it/s]\n"]}],"source":["with torch.no_grad():\n","        x_test_bert = torch.vstack([model_nohead(batch['input_ids'].to(device)).last_hidden_state[:,0].detach().to('cpu') for batch in tqdm(test_loader)])\n","\n","np.save(os.path.join(ds_path, 'x_test_emb.npy'), x_test_bert.numpy())"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(129066, 768) (129066, 219) (129066, 987)\n","(21511, 768) (21511, 219) (21511, 987)\n","(64533, 768) (64533, 219) (64533, 987)\n"]}],"source":["x_train_emb = np.load(os.path.join(ds_path, 'x_train_emb.npy'))\n","x_val_emb = np.load(os.path.join(ds_path, 'x_val_emb.npy'))\n","x_test_emb = np.load(os.path.join(ds_path, 'x_test_emb.npy'))\n","\n","x_train = np.hstack((x_train_feats, x_train_emb))\n","print(x_train_emb.shape, x_train_feats.shape, x_train.shape)\n","\n","x_val = np.hstack((x_val_feats, x_val_emb))\n","print(x_val_emb.shape, x_val_feats.shape, x_val.shape)\n","\n","x_test = np.hstack((x_test_feats, x_test_emb))\n","print(x_test_emb.shape, x_test_feats.shape, x_test.shape)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["ct = ColumnTransformer([\n","        ('scaler', StandardScaler(), list(range(x_train.shape[1])))\n","    ], remainder='passthrough')\n","\n","x_train_scaled = ct.fit_transform(x_train)\n","x_val_scaled = ct.transform(x_val)\n","x_test_scaled = ct.transform(x_test)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"0FiknOw_00lH","outputId":"74f2ac87-9320-4057-eb50-b54958bf8a8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.82      0.82      0.82     10755\n","           1       0.82      0.82      0.82     10756\n","\n","    accuracy                           0.82     21511\n","   macro avg       0.82      0.82      0.82     21511\n","weighted avg       0.82      0.82      0.82     21511\n","\n","[[8769 1986]\n"," [1912 8844]]\n"]}],"source":["clf_lr = LogisticRegression(max_iter=5000, random_state=0, verbose=0).fit(x_train_scaled, y_train)\n","clf_eval(clf_lr, x_val_scaled, y_val)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["['models/logreg.joblib']"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["dump(clf_lr, 'models/logreg.joblib')"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.8187903863139789\n"]}],"source":["clf_lr= load('models/logreg.joblib')\n","print(clf_lr.score(x_val_scaled, y_val))\n","\n","submission(clf_lr, x_test_scaled, df_test, 'logreg2')"]}],"metadata":{"accelerator":"GPU","colab":{"name":"ru_atd.ipynb","provenance":[]},"interpreter":{"hash":"2d3a13fa35461c6d7f441fbb3d93fc4f14860aa527e8f914775d5e57b8364c02"},"kernelspec":{"display_name":"Python 3.9.5 ('tf')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"orig_nbformat":4,"widgets":{"application/vnd.jupyter.widget-state+json":{"011bcd59702e4471bf344d7adc18ff4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"024b5beba4c3459099ac0a5312816bc6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43c9dd8b01eb4b049e59ede63b6fc3a9","max":22,"min":0,"orientation":"horizontal","style":"IPY_MODEL_39893bd6a9284642acc8d214b5e8aa53","value":22}},"07464f6c62024a798cee0acf98c011e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6a99adeb6cb487dbe402199371b4751","IPY_MODEL_c9150df8ab334a19838d1c9fc97fa4b1","IPY_MODEL_dd30acc473e043d78e929f886191a40f"],"layout":"IPY_MODEL_465078bfeb3d40439dc09f427ccfbe14"}},"0e591ca82dbf4cbd8d271d419335e7da":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f424e58531c4c3ba5ddfa6cdde28c36":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_48874d849d294cb2ae524ad2d0ecb36c","max":65,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1dd909aae6e94daf8ef367ea491266eb","value":65}},"0fbcbb759407479eb12db76f5c347f1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1aea4571b9ea493183b026a71058b604","placeholder":"​","style":"IPY_MODEL_1a4768f86f634af1a378f1ab87c98b9b","value":"100%"}},"1713bdd29a5c439382b6806bebd95edd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17de390efd7348a392aca4d76c36f276":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0fbcbb759407479eb12db76f5c347f1a","IPY_MODEL_f6dff8192b8b4e66bb75a53d919d2506","IPY_MODEL_39d7bcaa318a4dcd9ab8654ccb59b33b"],"layout":"IPY_MODEL_1713bdd29a5c439382b6806bebd95edd"}},"19de5c9ce041491b82b875e4e908dd31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83db1745ca8a46518228d00431d056d4","placeholder":"​","style":"IPY_MODEL_b9ea31aa509f48a6958ef0a5a2da9713","value":" 65/65 [00:19&lt;00:00,  1.80ba/s]"}},"1a4768f86f634af1a378f1ab87c98b9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1aea4571b9ea493183b026a71058b604":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dd909aae6e94daf8ef367ea491266eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e10688073f544018a38ef40e25bcb0c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f02ec40c23c4b19acd5841ba682c49c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25b6623edb6747d8ae6b63f458c8d752":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2768e23224c145dbbe7bf4c215d8e4a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"296191f91c98486c8b049cd46588faa3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7aa40022e0447489e2009e5ad95f300","placeholder":"​","style":"IPY_MODEL_011bcd59702e4471bf344d7adc18ff4d","value":"100%"}},"35e0bbce8e61460ea3a5eb193207e8cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ec4ac73432f48ffad3e570d5d8d6986","placeholder":"​","style":"IPY_MODEL_4b7a10def477422f92548316455516d4","value":"100%"}},"39893bd6a9284642acc8d214b5e8aa53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39d7bcaa318a4dcd9ab8654ccb59b33b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be4ce3f011984b3ba609ce8f7a07c9f0","placeholder":"​","style":"IPY_MODEL_c492521bea4d4b3184bbbb103a4d0836","value":" 130/130 [00:34&lt;00:00,  4.22ba/s]"}},"3d82ff3720024a0e8f4c1c886d15ea1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_296191f91c98486c8b049cd46588faa3","IPY_MODEL_0f424e58531c4c3ba5ddfa6cdde28c36","IPY_MODEL_ccaf3da3789949278f05bb209f1fa011"],"layout":"IPY_MODEL_0e591ca82dbf4cbd8d271d419335e7da"}},"43c9dd8b01eb4b049e59ede63b6fc3a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"465078bfeb3d40439dc09f427ccfbe14":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48874d849d294cb2ae524ad2d0ecb36c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b7a10def477422f92548316455516d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"530160f263e14ce0ab9dcb06215141c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6225b8f9625d4bc8b4f370c623239f80":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"651a4b33e03a4c30a3bc70d76290d948":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72f8bd31aa944771ae512a536a25376b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a83e698a1944cbea611ffbdc174b7c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7db33ec8a86d43f18f633c2fb7c9bd98":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80f10655527b44468a12bd58e5931527":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b921920c3f7842468f02deb23e284b04","placeholder":"​","style":"IPY_MODEL_530160f263e14ce0ab9dcb06215141c6","value":" 22/22 [00:04&lt;00:00,  5.08ba/s]"}},"83db1745ca8a46518228d00431d056d4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bb5f42b01664a67af782484da70cbce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25b6623edb6747d8ae6b63f458c8d752","max":65,"min":0,"orientation":"horizontal","style":"IPY_MODEL_72f8bd31aa944771ae512a536a25376b","value":65}},"8e842de07d6d41df9855b6f727487f7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ec4ac73432f48ffad3e570d5d8d6986":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"955eb95850f84ba3af23588c6b622ef2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96f0bbdf65c1415e85ce421220e51078":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5044d791c014c4c83aa531f99ed3d56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35e0bbce8e61460ea3a5eb193207e8cb","IPY_MODEL_8bb5f42b01664a67af782484da70cbce","IPY_MODEL_19de5c9ce041491b82b875e4e908dd31"],"layout":"IPY_MODEL_e41629ea77e643f8a0c45a502399bf4f"}},"a7649e3843b44f3d8d40cb823e60d7a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7aa40022e0447489e2009e5ad95f300":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b921920c3f7842468f02deb23e284b04":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9ea31aa509f48a6958ef0a5a2da9713":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be4ce3f011984b3ba609ce8f7a07c9f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c492521bea4d4b3184bbbb103a4d0836":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9150df8ab334a19838d1c9fc97fa4b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e10688073f544018a38ef40e25bcb0c","max":22,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f02ec40c23c4b19acd5841ba682c49c","value":22}},"cbd01516d8b840faaeb0293c7b059c80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f325051977c644d7b75bc4cc88d874bf","IPY_MODEL_024b5beba4c3459099ac0a5312816bc6","IPY_MODEL_80f10655527b44468a12bd58e5931527"],"layout":"IPY_MODEL_7db33ec8a86d43f18f633c2fb7c9bd98"}},"ccaf3da3789949278f05bb209f1fa011":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7649e3843b44f3d8d40cb823e60d7a7","placeholder":"​","style":"IPY_MODEL_2768e23224c145dbbe7bf4c215d8e4a1","value":" 65/65 [00:14&lt;00:00,  4.96ba/s]"}},"d6a99adeb6cb487dbe402199371b4751":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_955eb95850f84ba3af23588c6b622ef2","placeholder":"​","style":"IPY_MODEL_651a4b33e03a4c30a3bc70d76290d948","value":"100%"}},"dd30acc473e043d78e929f886191a40f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebf4b2bbef7d47d4aefc93b4ea0a1b3f","placeholder":"​","style":"IPY_MODEL_e9d9a59206b44d24900997c0c00b9c6f","value":" 22/22 [00:05&lt;00:00,  4.75ba/s]"}},"e41629ea77e643f8a0c45a502399bf4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9d9a59206b44d24900997c0c00b9c6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebf4b2bbef7d47d4aefc93b4ea0a1b3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f325051977c644d7b75bc4cc88d874bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96f0bbdf65c1415e85ce421220e51078","placeholder":"​","style":"IPY_MODEL_7a83e698a1944cbea611ffbdc174b7c2","value":"100%"}},"f6dff8192b8b4e66bb75a53d919d2506":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6225b8f9625d4bc8b4f370c623239f80","max":130,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e842de07d6d41df9855b6f727487f7b","value":130}}}}},"nbformat":4,"nbformat_minor":0}
